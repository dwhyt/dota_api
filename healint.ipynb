{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6be70a03-dd9c-4602-8c69-14cabbc57604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Assumptions:\n",
    "- each account is not shared (i.e. only 1 human playing games using one account)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5731f3-d2ce-4370-895f-06fb40b3e3aa",
   "metadata": {},
   "source": [
    "# Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65a5657-053b-4f9f-9b58-af2da80123cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "import requests\n",
    "import pandas\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import date, timedelta\n",
    "import numpy as np\n",
    "\n",
    "from surprise import NormalPredictor, Dataset, Reader, SVD, KNNBasic\n",
    "from surprise.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bdc3519-dd97-419f-ade2-cac7245af501",
   "metadata": {},
   "outputs": [],
   "source": [
    "#noticed that a lot of account_ids in match_info is None if matches are randomly sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816bad53-93d9-4d6c-aac4-bed34c357666",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part 1, leaderboard given a list of account_id's, ranked in descending order by win-loss ratio (by default all historical matches are considered. if starting date is specified, then will only conder matches from that point onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bb937a6-4f3d-42f5-a954-70632b72850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH_ID = 6898280972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c38e51a8-b224-48c7-970c-0c2d69912b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accounts_from_match(match_id: int) -> list:\n",
    "    \"\"\"\n",
    "        Returns the list of player account_ids from specified match\n",
    "        \n",
    "        Params:\n",
    "        match_id (int) - match_id to check\n",
    "        \n",
    "        Returns:\n",
    "        A list of ints, containing the account_ids of players\n",
    "    \"\"\"\n",
    "    \n",
    "    # request = requests.get(f\"https://api.opendota.com/api/matches/{match_id}?api_key={API_KEY}\")\n",
    "    request = requests.get(f\"https://api.opendota.com/api/matches/{match_id}\").json()\n",
    "    accounts_list = [player[\"account_id\"] for player in request[\"players\"]]\n",
    "    return(accounts_list)\n",
    "\n",
    "def check_player_wl(account_id: int, num_days_back: int=None) -> tuple:\n",
    "    \"\"\"\n",
    "        Calculates win-loss rate for a player given player's account_id, \n",
    "        given as ratio calculated using the following formula - number of wins divided by number of losses\n",
    "        \n",
    "        Params:\n",
    "        account_id (int) - player's account_id to check, passed in as int\n",
    "        \n",
    "        Returns:\n",
    "        A tuple with player's account_id and float representing win loss ratio of specified player, 3 decimal places\n",
    "    \"\"\"\n",
    "    if num_days_back:\n",
    "        player_wl_request = requests.get(f\"https://api.opendota.com/api/players/{account_id}/wl?date={num_days_back}\").json()\n",
    "    else:\n",
    "        player_wl_request = requests.get(f\"https://api.opendota.com/api/players/{account_id}/wl?\").json()\n",
    "    \n",
    "    return((account_id, round(player_wl_request[\"win\"]/player_wl_request[\"lose\"], 3)))\n",
    "\n",
    "def rank_players_by_wl(accounts_list: list, num_days_back: int=None) -> list:\n",
    "    \"\"\"\n",
    "        Calculates win-loss rate for a list of players given players' account_id's, \n",
    "        given as ratio calculated using the following formula - number of wins divided by number of losses, \n",
    "        ranked by ratio in descending order\n",
    "        \n",
    "        Params:\n",
    "        account_ids (list) - list of players account_id to check, passed in as int\n",
    "        \n",
    "        Returns:\n",
    "        List of account_ids and win-loss ratio, counted only using matches from \"num_days_back\" days ago till now,\n",
    "        sorted by win-loss ratio in descending order\n",
    "    \"\"\"\n",
    "    \n",
    "    players_ranked_by_wl = []\n",
    "    \n",
    "    for account in accounts_list:\n",
    "        players_ranked_by_wl.append(check_player_wl(account, num_days_back))\n",
    "    \n",
    "    return(sorted(players_ranked_by_wl, key=lambda x:x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bca032b-b6fa-4895-8794-55ed7276a1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(250544263, 1.666),\n",
       " (190258756, 1.539),\n",
       " (237578577, 1.397),\n",
       " (302429528, 1.318),\n",
       " (240727522, 1.289),\n",
       " (394257871, 1.287),\n",
       " (460481806, 1.15),\n",
       " (236322966, 1.134),\n",
       " (1062400248, 1.097),\n",
       " (133049595, 1.068)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accounts_list = accounts_from_match(MATCH_ID)\n",
    "ranked = rank_players_by_wl(accounts_list)\n",
    "ranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ef6f4-d09a-4771-8b7b-98876e6e9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "[250544263, 190258756, 237578577, 302429528]\n",
    " (240727522, 1.289),\n",
    " (394257871, 1.287),\n",
    " (460481806, 1.15),\n",
    " (236322966, 1.134),\n",
    " (1062400248, 1.097),\n",
    " (133049595, 1.068)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c5c143-a488-4a58-808f-4e6a172d88d9",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3067182-4582-4db2-a6fe-7de17f61603e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#testing account_id: 191312823\n",
    "\n",
    "def list_heroes_game() -> list:\n",
    "    \"\"\"\n",
    "        checks the heroes available in game\n",
    "        \n",
    "        Returns:\n",
    "        list of hero_ids in available in game\n",
    "    \"\"\"\n",
    "    \n",
    "    heroes = requests.get(f\"https://api.opendota.com/api/heroes\").json()\n",
    "    \n",
    "    return({hero[\"id\"]: hero[\"localized_name\"] for hero in heroes})\n",
    "\n",
    "def prepare_new_player_dict(list_heroes_game: list):\n",
    "    \"\"\"\n",
    "        Prepare a new empty dictionary to track hero counts for an account\n",
    "        \n",
    "        Params:\n",
    "        list_heroes_game (list) - list of hero_ids available in game\n",
    "        \n",
    "        Returns:\n",
    "        Empty dictionary for newly processed player, with the keys as a distinct hero\n",
    "    \"\"\"\n",
    "    \n",
    "    return({_:0 for _ in list_heroes_game})\n",
    "\n",
    "def get_hero_info(hero_id: int) -> list:\n",
    "    \"\"\"\n",
    "        Get two pieces information about a hero, \n",
    "        account_id that has played that hero and number of times that account_id has played that hero\n",
    "        \n",
    "        Params:\n",
    "        hero_id (int) - specific hero_id\n",
    "        \n",
    "        Returns:\n",
    "        Returns a list of lists, with each element of the main list being an account_id\n",
    "        and how many times that account has played that hero\n",
    "    \"\"\"\n",
    "    \n",
    "    match_info = requests.get(f\"https://api.opendota.com/api/heroes/{hero_id}/players\").json()\n",
    "    \n",
    "    return([[player[\"account_id\"], player[\"games_played\"]] for player in match_info])\n",
    "\n",
    "# def prepare_data_dict():\n",
    "#     \"\"\"\n",
    "#         Prepare dataset for recommendation system\n",
    "        \n",
    "#         Returns:\n",
    "#         Dictionary with account_id as key, and for each account_id is an inner dictionary with hero_ids as keys\n",
    "#         , this keeps track of the number of times that account_id has played that hero\n",
    "#     \"\"\"\n",
    "    \n",
    "#     dataset_dict = {}\n",
    "#     # all_matches = get_public_matches_samples(num_samples)\n",
    "    \n",
    "#     all_heroes_list = list_heroes_game()\n",
    "    \n",
    "#     for hero_id in tqdm(all_heroes_list):\n",
    "#         for account_id, games_played in get_hero_info(hero_id):\n",
    "#             if account_id not in dataset_dict:\n",
    "#                 dataset_dict[account_id] = prepare_new_player_dict(all_heroes_list)\n",
    "#             dataset_dict[account_id][hero_id] += games_played\n",
    "        \n",
    "#     return(dataset_dict)\n",
    "\n",
    "def get_public_matches_samples(query_end_date: date, query_period: int) -> list:\n",
    "    \"\"\"\n",
    "        searches for matches for the past XX days\n",
    "        \n",
    "        Params:\n",
    "        query_date (datetime.date) - date\n",
    "        \n",
    "        Returns:\n",
    "        List of dictionaries, with each dictionary specifying how many times an account has played a hero\n",
    "    \"\"\"\n",
    "    \n",
    "    query_start_date = query_end_date - timedelta(days=query_period)\n",
    "    \n",
    "    query_str = f\"\"\"\n",
    "    SELECT\n",
    "    player_matches.account_id,\n",
    "    player_matches.hero_id,\n",
    "    COUNT(DISTINCT player_matches.match_id)\n",
    "    FROM matches\n",
    "    JOIN player_matches using(match_id)\n",
    "    WHERE matches.start_time > extract(epoch from timestamp '{query_start_date.year}-{query_start_date.month}-{query_start_date.day}T00:00:00.000Z')\n",
    "    AND matches.start_time <= extract(epoch from timestamp '{query_end_date.year}-{query_end_date.month}-{query_end_date.day}T00:00:00.000Z')\n",
    "    GROUP BY player_matches.account_id, player_matches.hero_id\n",
    "    \"\"\"\n",
    "    \n",
    "    sample = requests.get(f\"https://api.opendota.com/api/explorer?sql={query_str}\").json()\n",
    "    \n",
    "    return(sample[\"rows\"])\n",
    "\n",
    "def prepare_accounts_hero_data(query_period: int=90):\n",
    "    \"\"\"\n",
    "        retrieves match data from matches which started after 'query_period' days ago, but started before today 0000hrs \n",
    "        \n",
    "        Params:\n",
    "        query_period (int) - number of days back to start collecting match data from\n",
    "        \n",
    "        Returns:\n",
    "        List of dictionaries, with each dictionary specifying how many times an account has played a hero, \n",
    "        based on match data retreived\n",
    "    \"\"\"\n",
    "    # dataset_list = []\n",
    "    all_heroes_list = list_heroes_game()\n",
    "    hero_played_counts_by_account = get_public_matches_samples(date.today(), query_period)\n",
    "    \n",
    "    return(pandas.DataFrame(hero_played_counts_by_account), all_heroes_list)\n",
    "\n",
    "def get_account_hero_hist(account_id: int, num_days_back: int=90) -> tuple:\n",
    "    \"\"\"\n",
    "        Retrieves 'num_days_back' days worth of match history for given 'account_id', \n",
    "        defaults to 90 days\n",
    "        \n",
    "        Params:\n",
    "        account_id (int) - player's account_id to check, passed in as int\n",
    "        num_days_back (int) - number of days of match data to retrieve\n",
    "        \n",
    "        Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    account_hist_matches = requests.get(f\"https://api.opendota.com/api/players/{account_id}/matches?date={num_days_back}\").json()\n",
    "    \n",
    "    account_dict = {}\n",
    "    \n",
    "    for match in account_hist_matches:\n",
    "        if match[\"hero_id\"] not in account_dict:\n",
    "            account_dict[match[\"hero_id\"]] = 0\n",
    "        account_dict[match[\"hero_id\"]] += 1\n",
    "    \n",
    "    account_df = pandas.DataFrame([{\"account_id\":account_id, \"hero_id\":key , 'count':value} for key, value in account_dict.items()])\n",
    "    \n",
    "    account_df[\"prop_of_matches\"] = account_df[\"count\"] / sum(account_df[\"count\"])\n",
    "    \n",
    "    return(account_df[[\"account_id\", \"hero_id\", \"prop_of_matches\"]])\n",
    "\n",
    "def recommendation_wrapper(account_id: int, query_period: int=90, min_num_matches: int=30, num_reccs: int=3):\n",
    "    \"\"\"\n",
    "        main wrapper method for hero recommendations\n",
    "        \n",
    "        Params:\n",
    "        account_id (int) - player's account_id to check for historical match data and subsequently recommend heroes for\n",
    "        query_period (int) - number of days of match data to retrieve\n",
    "        min_num_matches (int) - will only consider profiles with this minimum number of matches in recommendation matrix\n",
    "        num_reccs (int) - number of hero recommendations\n",
    "        \n",
    "        Returns:\n",
    "        A list of recommended heroes based on player match history and other player's match history. Will only recommend \n",
    "        heroes that have not been played.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    matches_dataset, hero_list = prepare_accounts_hero_data(query_period)\n",
    "    \n",
    "    #removes the account_id to recommend for if it already exists\n",
    "    matches_dataset = matches_dataset[matches_dataset[\"account_id\"] != account_id]\n",
    "    \n",
    "    #removes other account with less than min_num_matches\n",
    "    removal_set = matches_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "    matches_dataset = matches_dataset.merge(removal_set, on='account_id', how='left')\n",
    "    matches_dataset = matches_dataset[matches_dataset[\"count_y\"] >= min_num_matches]\n",
    "    \n",
    "    #calculate proportion of matches that a player selects that hero\n",
    "    matches_dataset[\"prop_of_matches\"] = matches_dataset[\"count_x\"] / matches_dataset[\"count_y\"]\n",
    "    matches_dataset = matches_dataset.drop([\"count_x\", \"count_y\"], axis=1)\n",
    "    \n",
    "    #gets match history of account to predict for\n",
    "    one_account_hist = get_account_hero_hist(account_id)\n",
    "    \n",
    "    matches_dataset = pandas.concat([matches_dataset, one_account_hist]).reset_index(drop=True)\n",
    "    \n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    data = Dataset.load_from_df(matches_dataset, reader)\n",
    "    final_set = data.build_full_trainset()\n",
    "    \n",
    "    sim_options = {'name': 'cosine',\n",
    "               'user_based': True  # compute  similarities between users\n",
    "               }\n",
    "\n",
    "    algo = KNNBasic(sim_options=sim_options)\n",
    "    algo.fit(final_set)\n",
    "    \n",
    "    anti_testset_user = []\n",
    "    # account to predict for is always the last\n",
    "    targetUser = max(final_set.all_users())\n",
    "    #initialise with global mean of matrix\n",
    "    fillValue = final_set.global_mean\n",
    "    \n",
    "    #checks which heroes already played, we only want to recommend heroes that have not been played in that period\n",
    "    user_item_ratings = final_set.ur[targetUser]\n",
    "    user_items = [item for (item,_) in (user_item_ratings)]\n",
    "    \n",
    "    ratings = final_set.all_ratings()\n",
    "    for iid in final_set.all_items():\n",
    "        if(iid not in user_items):\n",
    "            anti_testset_user.append((final_set.to_raw_uid(targetUser),final_set.to_raw_iid(iid),fillValue))\n",
    "    \n",
    "    #get predictions\n",
    "    predictions = algo.test(anti_testset_user)\n",
    "    recommendations = sorted([[pred.iid, pred.est] for pred in predictions], key=lambda x:x[1], reverse=True)\n",
    "    final_reccs = [hero_list[hero[0]] for hero in recommendations[:num_reccs]]\n",
    "    \n",
    "    return(final_reccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39c0ba65-3e51-4c45-8768-2df28a060828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "reccs = recommendation_wrapper(191312823)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "309fcfa2-3c8c-43fb-835f-f33ed8849d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_id</th>\n",
       "      <th>hero_id</th>\n",
       "      <th>count_x</th>\n",
       "      <th>count_y</th>\n",
       "      <th>prop_of_matches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88470</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88470</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88470</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88470</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>47</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88470</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   account_id  hero_id  count_x  count_y  prop_of_matches\n",
       "0       88470        9        1       47         0.021277\n",
       "1       88470       29        2       47         0.042553\n",
       "2       88470       36        2       47         0.042553\n",
       "3       88470       38        5       47         0.106383\n",
       "4       88470       40        1       47         0.021277"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preparing template for experiments\n",
    "\n",
    "QUERY_PERIOD = 90\n",
    "min_num_matches = 0\n",
    "\n",
    "#retrieves match data from matches which started after 'query_period' days ago, but started before today 0000hrs\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "\n",
    "#checks the number of matches played by each account in specified query period\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "\n",
    "#performs a left merge\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "\n",
    "#removes account which have not played a minimum number of matches in past XX days\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "\n",
    "#calculates the proportion of matches that an account plays a hero, \n",
    "#out of all the matches played by that account in the past XX days\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "#taking a look\n",
    "testing_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316db008-47fe-4bae-a0b7-61b90640ce30",
   "metadata": {},
   "source": [
    "## starting experiments to determine arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "37ad4972-c089-4be1-95ae-0126ef2b3435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.1730  0.1715  0.1755  0.1709  0.1692  0.1720  0.0021  \n",
      "MAE (testset)     0.1071  0.1059  0.1073  0.1059  0.1069  0.1066  0.0006  \n",
      "Fit time          0.06    0.06    0.06    0.06    0.06    0.06    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.17302411, 0.17147419, 0.17548656, 0.17088758, 0.16915575]),\n",
       " 'test_mae': array([0.10705875, 0.10589196, 0.10728106, 0.10593227, 0.10689463]),\n",
       " 'fit_time': (0.06307125091552734,\n",
       "  0.059430837631225586,\n",
       "  0.05923008918762207,\n",
       "  0.05994296073913574,\n",
       "  0.059877872467041016),\n",
       " 'test_time': (0.007136106491088867,\n",
       "  0.007169008255004883,\n",
       "  0.007038116455078125,\n",
       "  0.007091999053955078,\n",
       "  0.006957054138183594)}"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 1, 90 days worth of matches, without removing anything, using SVD\n",
    "\n",
    "QUERY_PERIOD = 90\n",
    "min_num_matches = 0\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "48ffedb9-33c0-405d-8ee9-40baa8efd018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0729  0.0736  0.0723  0.0734  0.0730  0.0730  0.0005  \n",
      "MAE (testset)     0.0543  0.0544  0.0536  0.0542  0.0540  0.0541  0.0003  \n",
      "Fit time          0.04    0.03    0.03    0.03    0.03    0.03    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.0728786 , 0.07356606, 0.0722594 , 0.07341729, 0.07300651]),\n",
       " 'test_mae': array([0.05425384, 0.05438524, 0.0536349 , 0.05420983, 0.05401668]),\n",
       " 'fit_time': (0.03887200355529785,\n",
       "  0.0338749885559082,\n",
       "  0.0334320068359375,\n",
       "  0.033193111419677734,\n",
       "  0.03377676010131836),\n",
       " 'test_time': (0.00437617301940918,\n",
       "  0.004194021224975586,\n",
       "  0.004163026809692383,\n",
       "  0.00407099723815918,\n",
       "  0.00409698486328125)}"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 2, 90 days worth of matches, removing accounts with less than 30 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 90\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "3266105b-7b8f-417e-b81c-97600c0a4107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0718  0.0745  0.0731  0.0724  0.0741  0.0732  0.0010  \n",
      "MAE (testset)     0.0536  0.0542  0.0543  0.0530  0.0541  0.0538  0.0005  \n",
      "Fit time          0.03    0.02    0.02    0.03    0.02    0.03    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.0718463 , 0.0745211 , 0.07309424, 0.07235271, 0.07408453]),\n",
       " 'test_mae': array([0.05363811, 0.05421172, 0.0542618 , 0.05295164, 0.05405767]),\n",
       " 'fit_time': (0.031355857849121094,\n",
       "  0.024631023406982422,\n",
       "  0.024729013442993164,\n",
       "  0.025238990783691406,\n",
       "  0.024960994720458984),\n",
       " 'test_time': (0.0032401084899902344,\n",
       "  0.0030651092529296875,\n",
       "  0.0030527114868164062,\n",
       "  0.0031359195709228516,\n",
       "  0.0031189918518066406)}"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 3, 90 days worth of matches, removing accounts with less than 50 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 90\n",
    "min_num_matches = 50\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "ca78ef14-9f99-4475-9774-8de435f22f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0756  0.0742  0.0764  0.0793  0.0774  0.0766  0.0017  \n",
      "MAE (testset)     0.0546  0.0533  0.0560  0.0576  0.0561  0.0555  0.0015  \n",
      "Fit time          0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.07559876, 0.07419589, 0.07642082, 0.07927195, 0.07738745]),\n",
       " 'test_mae': array([0.05462852, 0.05333192, 0.05604093, 0.05760917, 0.05607604]),\n",
       " 'fit_time': (0.02202916145324707,\n",
       "  0.016865968704223633,\n",
       "  0.01613306999206543,\n",
       "  0.01612710952758789,\n",
       "  0.01611804962158203),\n",
       " 'test_time': (0.0023827552795410156,\n",
       "  0.0020067691802978516,\n",
       "  0.0019969940185546875,\n",
       "  0.002034902572631836,\n",
       "  0.00208282470703125)}"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 4, 90 days worth of matches, removing accounts with less than 70 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 90\n",
    "min_num_matches = 70\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "0626e893-d185-41a7-b0d6-c69e643b26d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0753  0.0706  0.0758  0.0703  0.0718  0.0727  0.0023  \n",
      "MAE (testset)     0.0557  0.0522  0.0554  0.0516  0.0528  0.0535  0.0017  \n",
      "Fit time          0.04    0.03    0.03    0.03    0.03    0.03    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.0752563 , 0.07061243, 0.07578992, 0.07026797, 0.07180428]),\n",
       " 'test_mae': array([0.05566211, 0.05220058, 0.05536435, 0.05161284, 0.05283402]),\n",
       " 'fit_time': (0.03564310073852539,\n",
       "  0.028768062591552734,\n",
       "  0.028650999069213867,\n",
       "  0.028474092483520508,\n",
       "  0.02888798713684082),\n",
       " 'test_time': (0.003643035888671875,\n",
       "  0.0035331249237060547,\n",
       "  0.003596067428588867,\n",
       "  0.0035300254821777344,\n",
       "  0.0035822391510009766)}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 5, 90 days worth of matches, removing accounts with less than 40 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 90\n",
    "min_num_matches = 40\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a69aade0-d22b-41e5-8a2b-6485b416f29f",
   "metadata": {},
   "source": [
    "Conclusion from experiments 1-5:\n",
    "\n",
    "From a logical perspective, we should remove accounts with less than a certain number of matches in the past XX days. This is in line with intuition because if an account does not have a minimal number of matches, it would not serve as a good example of the type of heroes typically played by account holders of similar personality.\n",
    "\n",
    "From a machine learning perspective, recommendation systems typically require the sparsity of the user-item matrix to be below 99.5%~. Intuitively, the higher the number of matches played by an account, we can generally expect a wider pool of heroes to be played by that account.\n",
    "\n",
    "From the metrics returned, will arbitrarily decide to remove accounts with less then 30 matches played in the past XX days as increasing the minimal number of matches beyond 30 does not yield any noticeable reduction in RMSE and MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "fc2591f5-231a-474d-9099-9dfe10860cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0883  0.0895  0.0869  0.0857  0.0920  0.0885  0.0022  \n",
      "MAE (testset)     0.0654  0.0657  0.0640  0.0635  0.0669  0.0651  0.0012  \n",
      "Fit time          0.02    0.02    0.01    0.01    0.01    0.01    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.08829555, 0.08950326, 0.08686597, 0.08570559, 0.09198775]),\n",
       " 'test_mae': array([0.06542861, 0.0657178 , 0.06402847, 0.06352132, 0.0669485 ]),\n",
       " 'fit_time': (0.021724939346313477,\n",
       "  0.01572704315185547,\n",
       "  0.01287698745727539,\n",
       "  0.012186288833618164,\n",
       "  0.012111186981201172),\n",
       " 'test_time': (0.002454996109008789,\n",
       "  0.0018129348754882812,\n",
       "  0.001489877700805664,\n",
       "  0.0014998912811279297,\n",
       "  0.0014810562133789062)}"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 6, 30 days worth of matches, removing accounts with less than 30 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 30\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "49bd7f8b-91ee-44a7-bb3c-14ddbd8b5ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0852  0.0799  0.0812  0.0821  0.0808  0.0818  0.0018  \n",
      "MAE (testset)     0.0625  0.0593  0.0593  0.0604  0.0600  0.0603  0.0012  \n",
      "Fit time          0.03    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.08517045, 0.07987274, 0.08124019, 0.08205054, 0.0807569 ]),\n",
       " 'test_mae': array([0.06253268, 0.05930301, 0.05931496, 0.0603534 , 0.05996569]),\n",
       " 'fit_time': (0.02925586700439453,\n",
       "  0.02188706398010254,\n",
       "  0.020620107650756836,\n",
       "  0.0203092098236084,\n",
       "  0.020586013793945312),\n",
       " 'test_time': (0.003036975860595703,\n",
       "  0.0026679039001464844,\n",
       "  0.0025370121002197266,\n",
       "  0.002479076385498047,\n",
       "  0.002541065216064453)}"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 7, 60 days worth of matches, removing accounts with less than 30 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 60\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "9c322d0b-966c-4523-8aab-89d369537979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0734  0.0706  0.0739  0.0722  0.0744  0.0729  0.0014  \n",
      "MAE (testset)     0.0549  0.0532  0.0555  0.0528  0.0545  0.0542  0.0010  \n",
      "Fit time          0.04    0.03    0.03    0.03    0.03    0.03    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.07338813, 0.07061515, 0.07394346, 0.07217432, 0.07440729]),\n",
       " 'test_mae': array([0.05491757, 0.05315664, 0.05545326, 0.0527895 , 0.05448349]),\n",
       " 'fit_time': (0.038659095764160156,\n",
       "  0.03312206268310547,\n",
       "  0.03301811218261719,\n",
       "  0.03300189971923828,\n",
       "  0.03309798240661621),\n",
       " 'test_time': (0.004099845886230469,\n",
       "  0.00406193733215332,\n",
       "  0.0040760040283203125,\n",
       "  0.0040662288665771484,\n",
       "  0.004050016403198242)}"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 8, 90 days worth of matches, removing accounts with less than 30 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 90\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "714c0b0f-7110-41be-8949-1338782b8215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0678  0.0664  0.0678  0.0686  0.0660  0.0673  0.0010  \n",
      "MAE (testset)     0.0503  0.0491  0.0506  0.0501  0.0485  0.0497  0.0008  \n",
      "Fit time          0.05    0.04    0.04    0.04    0.04    0.04    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.0678343 , 0.06641413, 0.06777189, 0.06858286, 0.06601311]),\n",
       " 'test_mae': array([0.05030895, 0.04913995, 0.05060456, 0.05014525, 0.04848993]),\n",
       " 'fit_time': (0.0469660758972168,\n",
       "  0.04396796226501465,\n",
       "  0.043845176696777344,\n",
       "  0.04379582405090332,\n",
       "  0.04386305809020996),\n",
       " 'test_time': (0.005434751510620117,\n",
       "  0.005507946014404297,\n",
       "  0.005357027053833008,\n",
       "  0.005385160446166992,\n",
       "  0.0055119991302490234)}"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 9, 120 days worth of matches, removing accounts with less than 30 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 120\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "61c35dd1-3a44-4d66-a33d-bc5fd210b505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0616  0.0632  0.0613  0.0633  0.0629  0.0625  0.0009  \n",
      "MAE (testset)     0.0459  0.0466  0.0453  0.0469  0.0466  0.0463  0.0006  \n",
      "Fit time          0.06    0.06    0.06    0.06    0.06    0.06    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.06156475, 0.063237  , 0.06131998, 0.0633304 , 0.06286434]),\n",
       " 'test_mae': array([0.04585284, 0.04658316, 0.04534866, 0.04690428, 0.04662134]),\n",
       " 'fit_time': (0.05696296691894531,\n",
       "  0.056520938873291016,\n",
       "  0.056720733642578125,\n",
       "  0.05803203582763672,\n",
       "  0.05813908576965332),\n",
       " 'test_time': (0.0071680545806884766,\n",
       "  0.007092952728271484,\n",
       "  0.0072100162506103516,\n",
       "  0.007173061370849609,\n",
       "  0.00727391242980957)}"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 10, 150 days worth of matches, removing accounts with less than 30 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 150\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "71c6e5e4-2aff-4e1d-9d70-9bbc824bac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0594  0.0586  0.0591  0.0594  0.0580  0.0589  0.0005  \n",
      "MAE (testset)     0.0435  0.0432  0.0439  0.0438  0.0430  0.0435  0.0003  \n",
      "Fit time          0.07    0.07    0.07    0.07    0.07    0.07    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.05936766, 0.05862909, 0.05908878, 0.05938492, 0.05803612]),\n",
       " 'test_mae': array([0.04352257, 0.04324701, 0.04387633, 0.04384825, 0.0429947 ]),\n",
       " 'fit_time': (0.0684809684753418,\n",
       "  0.0740506649017334,\n",
       "  0.06983304023742676,\n",
       "  0.06885004043579102,\n",
       "  0.06918978691101074),\n",
       " 'test_time': (0.008687019348144531,\n",
       "  0.009164094924926758,\n",
       "  0.008887052536010742,\n",
       "  0.008808135986328125,\n",
       "  0.008867025375366211)}"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 11, 180 days worth of matches, removing accounts with less than 30 matches, using SVD\n",
    "\n",
    "QUERY_PERIOD = 180\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = SVD()\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2c97e21b-ca87-46eb-ba99-db1e9ad808bb",
   "metadata": {},
   "source": [
    "Conclusion from experiments 6-11:\n",
    "\n",
    "Generally, RMSE and MAE decrease as the size of the training data set increases. From a machine learning perspective, this is in line with intuition as we usually want larger datasets to train our model with.\n",
    "\n",
    "From an operational perspective, both the fit and test time are acceptable.\n",
    "\n",
    "However, matches from recent matches (i.e. past 30 days) are probably more relevant and reflect changes in players' behaviours and preferences as new patches are released. On the other hand, we cannot take too little days of match data as there is a non-zero probability of one or a few heroes not being played in those few days of matches, which would result in them not being recommended.\n",
    "\n",
    "Hence, we arbitrarily decide to take 30 days worth of matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f2c14eb-1247-4263-8521-74a7f8547fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluating RMSE, MAE of algorithm KNNBasic on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0520  0.0497  0.0514  0.0476  0.0504  0.0502  0.0015  \n",
      "MAE (testset)     0.0353  0.0339  0.0346  0.0335  0.0340  0.0342  0.0006  \n",
      "Fit time          0.01    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.04    0.04    0.04    0.04    0.04    0.04    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.05198584, 0.04967989, 0.05143455, 0.04761632, 0.05039511]),\n",
       " 'test_mae': array([0.0352525 , 0.03388113, 0.03456327, 0.0334638 , 0.03400024]),\n",
       " 'fit_time': (0.005181074142456055,\n",
       "  0.0029239654541015625,\n",
       "  0.0029230117797851562,\n",
       "  0.0028748512268066406,\n",
       "  0.0028619766235351562),\n",
       " 'test_time': (0.043627023696899414,\n",
       "  0.03659200668334961,\n",
       "  0.036835670471191406,\n",
       "  0.03629112243652344,\n",
       "  0.03632473945617676)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 12, 60 days worth of matches, removing accounts with less than 30 matches, using KNN\n",
    "\n",
    "QUERY_PERIOD = 60\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_accounts_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True  # compute  similarities between users\n",
    "               }\n",
    "\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "acecbf8f-5963-4606-bd5e-2e63f3154924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NormalPredictor on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.0692  0.0674  0.0682  0.0682  0.0673  0.0681  0.0007  \n",
      "MAE (testset)     0.0506  0.0496  0.0496  0.0497  0.0503  0.0500  0.0004  \n",
      "Fit time          0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n",
      "Test time         0.00    0.00    0.00    0.00    0.00    0.00    0.00    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.06917514, 0.06739308, 0.06820463, 0.06815011, 0.06734511]),\n",
       " 'test_mae': array([0.05058685, 0.04956867, 0.04961651, 0.04970694, 0.05028406]),\n",
       " 'fit_time': (0.0030558109283447266,\n",
       "  0.0027959346771240234,\n",
       "  0.002401113510131836,\n",
       "  0.002157926559448242,\n",
       "  0.002009868621826172),\n",
       " 'test_time': (0.002613067626953125,\n",
       "  0.002309083938598633,\n",
       "  0.0020749568939208984,\n",
       "  0.001920938491821289,\n",
       "  0.0018339157104492188)}"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#experiment 13, 60 days worth of matches, removing accounts with less than 30 matches, using NormalPredictor\n",
    "\n",
    "QUERY_PERIOD = 60\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_account_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "# train_set = data.build_full_trainset()\n",
    "\n",
    "algo = NormalPredictor()\n",
    "\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d5795156-3339-43ad-80b4-a23ac069d34a",
   "metadata": {},
   "source": [
    "Conclusion from experiments 11-13:\n",
    "\n",
    "We will select the KNN-based algorithm as its yields the lowest RMSE and MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "f0f1636f-0f24-4c95-b216-c20b89ffd6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x1777e2be0>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Final selection, 30 days worth of matches, removing accounts with less than 30 matches, using KNN\n",
    "\n",
    "QUERY_PERIOD = 30\n",
    "min_num_matches = 30\n",
    "\n",
    "testing_dataset, hero_list = prepare_account_hero_data(query_period=QUERY_PERIOD)\n",
    "removal_set = testing_dataset.groupby(\"account_id\").sum()[\"count\"].reset_index()\n",
    "testing_dataset = testing_dataset.merge(removal_set, on='account_id', how='left')\n",
    "testing_dataset = testing_dataset[testing_dataset[\"count_y\"] >= min_num_matches]\n",
    "testing_dataset[\"prop_of_matches\"] = testing_dataset[\"count_x\"] / testing_dataset[\"count_y\"]\n",
    "\n",
    "# testing_dataset.head()\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(testing_dataset[[\"account_id\", \"hero_id\", \"prop_of_matches\"]], reader)\n",
    "final_set = data.build_full_trainset()\n",
    "\n",
    "sim_options = {'name': 'cosine',\n",
    "               'user_based': True  # compute  similarities between users\n",
    "               }\n",
    "\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(final_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6de6f3-7c2e-42f8-836b-dd0083e2e12e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "da8432da-eeb3-45fe-be37-fc5cef100317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "358"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "b5919bd1-b2e8-4aee-9e9d-c81a50b426e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "account_to_predict = max(final_set.all_users())\n",
    "\n",
    "anti_testset_user = []\n",
    "targetUser = 0 #inner_id of the target user\n",
    "fillValue = final_set.global_mean\n",
    "user_item_ratings = final_set.ur[targetUser]\n",
    "user_items = [item for (item,_) in (user_item_ratings)]\n",
    "ratings = final_set.all_ratings()\n",
    "for iid in final_set.all_items():\n",
    "    if(iid not in user_items):\n",
    "        anti_testset_user.append((final_set.to_raw_uid(targetUser),final_set.to_raw_iid(iid),fillValue))\n",
    "\n",
    "predictions = algo.test(anti_testset_user)\n",
    "recommendations = sorted([[pred.iid, pred.est] for pred in predictions], key=lambda x:x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "85d8bc3d-164a-47df-92a1-b484783451d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[128, 0.17795044933634585],\n",
       " [21, 0.162765311768566],\n",
       " [17, 0.15291157241551329],\n",
       " [23, 0.13840233049502804],\n",
       " [62, 0.13836600593849632],\n",
       " [11, 0.13729040197852294],\n",
       " [86, 0.13588638930305746],\n",
       " [48, 0.12210444307853643],\n",
       " [105, 0.11429800309962543],\n",
       " [136, 0.10884163658724025],\n",
       " [83, 0.10787653203648712],\n",
       " [104, 0.10712133402585136],\n",
       " [18, 0.10429261982968505],\n",
       " [56, 0.10285099529813452],\n",
       " [87, 0.10211609089444121],\n",
       " [71, 0.10209613154414734],\n",
       " [61, 0.10190347936481257],\n",
       " [126, 0.09660477783489936],\n",
       " [120, 0.09655384575006487],\n",
       " [97, 0.09409662309950526],\n",
       " [79, 0.09387861175884868],\n",
       " [40, 0.08720957591523029],\n",
       " [95, 0.08691168589323389],\n",
       " [16, 0.08648977847107844],\n",
       " [33, 0.08444071221768071],\n",
       " [19, 0.0843352553779434],\n",
       " [68, 0.08267717237027691],\n",
       " [32, 0.08097023403060088],\n",
       " [113, 0.07972394111820244],\n",
       " [34, 0.07806498059455674],\n",
       " [25, 0.07325700340064323],\n",
       " [101, 0.0714063969982861],\n",
       " [31, 0.0690429905448874],\n",
       " [114, 0.06808842078999189],\n",
       " [67, 0.06706878024570101],\n",
       " [102, 0.06691782925048395],\n",
       " [77, 0.06681485486640576],\n",
       " [22, 0.06677644529396569],\n",
       " [78, 0.06556688943980934],\n",
       " [54, 0.06530541572060283],\n",
       " [51, 0.06425734853408668],\n",
       " [94, 0.05913574242102191],\n",
       " [90, 0.05811347467632785],\n",
       " [82, 0.05790658846417736],\n",
       " [50, 0.05691871097134044],\n",
       " [112, 0.05532802001037107],\n",
       " [5, 0.05467488080731449],\n",
       " [73, 0.053748797932924995],\n",
       " [47, 0.052770087475915564],\n",
       " [44, 0.05206896045244839],\n",
       " [123, 0.051075385783415445],\n",
       " [14, 0.050274682983018446],\n",
       " [12, 0.04257382995319338],\n",
       " [49, 0.04216515423293911],\n",
       " [43, 0.04199491057526675],\n",
       " [74, 0.039172670572468975],\n",
       " [99, 0.037011340253825256],\n",
       " [107, 0.03687300767492664],\n",
       " [1, 0.036630316913413376],\n",
       " [36, 0.032762934726053995],\n",
       " [10, 0.03241190633033529],\n",
       " [88, 0.03199952359475352],\n",
       " [121, 0.03160901734490124],\n",
       " [2, 0.02998433520689815],\n",
       " [91, 0.028632740058506488],\n",
       " [26, 0.02829614442682187],\n",
       " [7, 0.02620561272130992],\n",
       " [53, 0.024622153502035546],\n",
       " [57, 0.024524655611690677],\n",
       " [80, 0.024062442745828878],\n",
       " [72, 0.02338773284204768],\n",
       " [27, 0.022968652130460926],\n",
       " [45, 0.021683156933281513],\n",
       " [4, 0.021323069268338685],\n",
       " [28, 0.020423920406662785],\n",
       " [109, 0.018364165128000595],\n",
       " [84, 0.018014047880725678],\n",
       " [37, 0.01726237176942044],\n",
       " [106, 0.013014259341957865],\n",
       " [3, 0.011757945446263303],\n",
       " [76, 0.011246113894251897],\n",
       " [20, 0.010994977292409211],\n",
       " [30, 0.01059436631586768],\n",
       " [96, 0.01027355464454733],\n",
       " [6, 0.01003999645258015],\n",
       " [64, 0.009552686495334972],\n",
       " [15, 0.009280531268043062],\n",
       " [58, 0.009045863272318815],\n",
       " [8, 0.006036375960098622],\n",
       " [42, 0.0042487049193465146],\n",
       " [35, 0.0036664626925527882],\n",
       " [110, 0.003646442792909453],\n",
       " [13, 0.0032432631426860675],\n",
       " [75, 0.0018325389812459056],\n",
       " [93, 0.0015776013851923204],\n",
       " [39, 0.0015190096495820773],\n",
       " [55, 0],\n",
       " [92, 0],\n",
       " [66, 0],\n",
       " [85, 0],\n",
       " [46, 0],\n",
       " [41, 0],\n",
       " [63, 0],\n",
       " [70, 0],\n",
       " [89, 0],\n",
       " [111, 0],\n",
       " [103, 0],\n",
       " [119, 0],\n",
       " [59, 0]]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be8ff5-60be-4bd7-85d7-edf089e51245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321db354-a91e-43fc-bb89-ffe89ce9f5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152e1a1-572d-4f43-87fa-33a60a72a873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701eccc2-e1d5-4c9e-b5d0-fe136f0d8250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "013bfab0-9fd0-4437-8a33-263a251100a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d550b4-6516-4f1d-971d-44cca492c449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08714999-d0de-4b77-95ca-c894de7b0ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d76af0-63fa-48ba-ac28-ce425583b84f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "64eb8240-442d-4da6-8e4b-704e27eaeda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d90398-4815-4646-b74f-2f44e191e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495db2b5-59c4-49c4-bb72-f50a86ab83bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d864d7e6-6e2d-4394-82ce-69b7a09450bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff27c3e-a69d-48ab-af48-403d28062a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5563e75f-6704-414e-a443-1c1512a69382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513346b5-4606-436c-80a6-eead5a6b8c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e8d77-45d8-4443-a1e9-f5af2d65c44c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648cedd5-4ed1-4881-9eb3-5de91f615a55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98630d61-b7b5-4cb7-ae21-e5c992be757c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f64c2-7944-4af7-99f5-187c09a494b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933e32b-a5f1-47c0-80c5-e6e9ecf6bc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f329d-9b62-4530-8e84-b1e4df9d85d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec49bfe-4c72-4a11-b529-38af1edbac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##workings \n",
    "query_str = f\"\"\"\n",
    "SELECT\n",
    "matches.match_id,\n",
    "matches.start_time,\n",
    "player_matches.hero_id,\n",
    "player_matches.account_id\n",
    "FROM matches\n",
    "JOIN player_matches using(match_id)\n",
    "JOIN heroes on heroes.id = player_matches.hero_id\n",
    "AND matches.start_time >= extract(epoch from timestamp '2022-11-07T00:00:00.000Z')\n",
    "AND matches.start_time <= extract(epoch from timestamp '2022-11-07T00:00:00.000Z')\n",
    "ORDER BY matches.match_id NULLS LAST\n",
    "LIMIT 250\n",
    "\"\"\"\n",
    "\n",
    "query_str = f\"\"\"\n",
    "SELECT\n",
    "matches.match_id,\n",
    "matches.start_time,\n",
    "player_matches.hero_id,\n",
    "player_matches.account_id\n",
    "FROM matches\n",
    "JOIN player_matches using(match_id)\n",
    "JOIN heroes on heroes.id = player_matches.hero_id\n",
    "AND matches.start_time >= extract(epoch from timestamp '{query_start_date.year}-{query_start_date.month}-{query_start_date.day}T00:00:00.000Z')\n",
    "AND matches.start_time <= extract(epoch from timestamp '{query_end_date.year}-{query_end_date.month}-{query_end_date.day}T00:00:00.000Z')\n",
    "ORDER BY matches.match_id NULLS LAST\n",
    "LIMIT 5000\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
